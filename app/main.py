from fastapi import FastAPI, HTTPException, File, UploadFile, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Dict, List, Optional
from app.predictor import CreditScoringPredictor
from app.auth import (
    get_current_user, get_current_admin_user, authenticate_user,
    create_access_token, Token, LoginRequest, User, ACCESS_TOKEN_EXPIRE_MINUTES
)
import logging
import pandas as pd
from datetime import datetime, timedelta
from fastapi import Body

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Credit Scoring API",
    description="AI-based credit scoring system for small retailers",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware - allow frontend to connect
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify exact origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize predictor
try:
    predictor = CreditScoringPredictor(models_dir='models')
    logger.info("‚úÖ Models loaded successfully")
except Exception as e:
    logger.error(f"‚ùå Failed to load models: {e}")
    raise


# ========================================================================
# PYDANTIC MODELS FOR REQUEST/RESPONSE
# ========================================================================

class ClientData(BaseModel):
    """Client financial data for prediction"""
    data: Dict[str, float] = Field(..., description="Client features as key-value pairs")

    class Config:
        json_schema_extra = {
            "example": {
                "data": {
                    "INCOME": 180000,
                    "SAVINGS": 450000,
                    "DEBT": 320000,
                    "R_DEBT_INCOME": 1.78
                }
            }
        }


class PredictionResponse(BaseModel):
    """Prediction response model"""
    default_probability: float
    default_class: int
    risk_level: str
    decision: str
    credit_score: float
    score_range: str


class BatchPredictionRequest(BaseModel):
    """Batch prediction request"""
    clients: List[Dict[str, float]]


class ModelInfo(BaseModel):
    """Model metadata"""
    created_at: str
    models: dict
    features: List[str]
    n_features: int
    dataset_info: Optional[dict] = None


class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    timestamp: str
    version: str


# ========================================================================
# ENDPOINTS
# ========================================================================

@app.post("/auth/login", response_model=Token, tags=["Authentication"])
async def login(login_data: LoginRequest):
    """
    –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    **–¢–µ—Å—Ç–æ–≤—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
    - admin / secret (–ø–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø)
    - user / password (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø)
    """
    user = authenticate_user(login_data.username, login_data.password)
    if not user:
        raise HTTPException(
            status_code=401,
            detail="–ù–µ–≤–µ—Ä–Ω–æ–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –ø–∞—Ä–æ–ª—å"
        )
    
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user["username"], "role": user["role"]},
        expires_delta=access_token_expires
    )
    
    logger.info(f"User {user['username']} logged in successfully")
    return {"access_token": access_token, "token_type": "bearer"}


@app.get("/auth/me", tags=["Authentication"])
async def get_me(current_user: User = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    return {
        "username": current_user.username,
        "role": current_user.role
    }


@app.get("/", tags=["General"])
async def root():
    """Root endpoint with API information"""
    return {
        "message": "Credit Scoring API",
        "status": "running",
        "version": "1.0.0",
        "authentication": {
            "login": "/auth/login",
            "me": "/auth/me"
        },
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "predict": "/predict",
            "batch": "/predict/batch",
            "model_info": "/model-info",
            "features": "/features"
        }
    }

TOP_FEATURES = [
    "R_DEBT_INCOME", "DEBT", "INCOME", "R_EXPENDITURE",
    "SAVINGS", "R_SAVINGS_INCOME", "R_GROCERIES", "R_HOUSING",
    "T_EXPENDITURE_12", "R_GAMBLING", "T_HOUSING_12", "T_GROCERIES_12"
]

@app.post("/predict_slim", tags=["Prediction"])
async def predict_slim(user_data: dict = Body(...), current_user: User = Depends(get_current_user)):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ 12 —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–º–∏.
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**
    """
    # –ü–æ–¥–≥—Ä—É–∑–∏ —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (feature_means –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ, –∫–∞–∫ –≤ –ø—Ä–æ—à–ª–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏)
    feature_means_only = {k: v for k, v in predictor.feature_means.items() if k in predictor.metadata['features']}
    features = feature_means_only.copy()
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ
    for key in TOP_FEATURES:
        if key in user_data:
            features[key] = user_data[key]
    print("–°–æ–±–∏—Ä–∞–µ–º —Ç–∞–∫–æ–π –≤–µ–∫—Ç–æ—Ä:", features)
    result = predictor.predict_full(features)
    logger.info(f"Slim prediction by {current_user.username}")
    return result

@app.get("/health", response_model=HealthResponse, tags=["General"])
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }


@app.get("/model-info", response_model=ModelInfo, tags=["Model Information"])
async def get_model_info(current_user: User = Depends(get_current_admin_user)):
    """
    Get detailed model metadata and performance metrics
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–æ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞**

    Returns information about:
    - Model training date
    - Performance metrics (ROC-AUC, R¬≤, etc.)
    - Feature list
    - Dataset statistics
    """
    try:
        return predictor.get_model_info()
    except Exception as e:
        logger.error(f"Error getting model info: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/features", tags=["Model Information"])
async def get_features():
    """
    Get list of all required features for prediction

    Returns the complete list of 84 features needed for prediction
    """
    try:
        metadata = predictor.get_model_info()
        return {
            "features": metadata['features'],
            "count": metadata['n_features'],
            "example_values": {
                "INCOME": 180000,
                "SAVINGS": 450000,
                "DEBT": 320000,
                "R_DEBT_INCOME": 1.78
            }
        }
    except Exception as e:
        logger.error(f"Error getting features: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
async def predict(client_data: ClientData, current_user: User = Depends(get_current_user)):
    """
    Predict credit risk and score for a single client
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**

    **Required**: All 84 features must be provided in the request

    **Returns**:
    - Credit score (300-800 range)
    - Default probability (0-100%)
    - Risk level (Low/Medium/High)
    - Decision (APPROVE/REVIEW/REJECT)
    """
    try:
        # Make prediction
        result = predictor.predict_full(client_data.data)

        logger.info(f"Prediction made by {current_user.username}: {result['decision']} (Score: {result['credit_score']:.2f})")
        return result

    except Exception as e:
        logger.error(f"Prediction error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/default", tags=["Prediction"])
async def predict_default_only(client_data: ClientData, current_user: User = Depends(get_current_user)):
    """
    Predict only default probability (faster than full prediction)
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**

    Returns default probability and risk classification
    """
    try:
        result = predictor.predict_default(client_data.data)
        logger.info(f"Default prediction by {current_user.username}: {result['default_probability']:.2f}%")
        return result
    except Exception as e:
        logger.error(f"Default prediction error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/score", tags=["Prediction"])
async def predict_score_only(client_data: ClientData, current_user: User = Depends(get_current_user)):
    """
    Predict only credit score (faster than full prediction)
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**

    Returns credit score prediction
    """
    try:
        result = predictor.predict_credit_score(client_data.data)
        logger.info(f"Score prediction by {current_user.username}: {result['credit_score']:.2f}")
        return result
    except Exception as e:
        logger.error(f"Score prediction error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/batch", tags=["Prediction"])
async def predict_batch(request: BatchPredictionRequest, current_user: User = Depends(get_current_user)):
    """
    Predict credit risk for multiple clients at once
    
    **–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**

    **Input**: Array of client data objects
    **Returns**: Array of predictions

    Useful for processing multiple loan applications simultaneously
    """
    try:
        results = []
        for i, client_data in enumerate(request.clients):
            try:
                result = predictor.predict_full(client_data)
                result['client_index'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"Error processing client {i}: {e}")
                results.append({
                    'client_index': i,
                    'error': str(e)
                })

        logger.info(f"Batch prediction by {current_user.username} completed: {len(results)} clients")
        return {
            "total": len(request.clients),
            "successful": len([r for r in results if 'error' not in r]),
            "predictions": results
        }

    except Exception as e:
        logger.error(f"Batch prediction error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/statistics", tags=["Analytics"])
async def get_statistics():
    """
    Get model statistics and thresholds

    Returns decision thresholds and risk level definitions
    """
    return {
        "risk_thresholds": {
            "low": {
                "max_default_probability": 30,
                "decision": "APPROVE",
                "description": "Low risk - Recommended for approval"
            },
            "medium": {
                "min_default_probability": 30,
                "max_default_probability": 50,
                "decision": "REVIEW",
                "description": "Medium risk - Requires review"
            },
            "high": {
                "min_default_probability": 50,
                "decision": "REJECT",
                "description": "High risk - Not recommended"
            }
        },
        "score_range": {
            "min": 300,
            "max": 800,
            "description": "Credit score range"
        },
        "model_performance": predictor.metadata.get('models', {})
    }


# ========================================================================
# ERROR HANDLERS
# ========================================================================

@app.exception_handler(404)
async def not_found_handler(request, exc):
    return {
        "error": "Endpoint not found",
        "path": str(request.url),
        "available_endpoints": [
            "/docs",
            "/health",
            "/predict",
            "/predict/batch",
            "/model-info"
        ]
    }


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"Internal server error: {exc}")
    return {
        "error": "Internal server error",
        "message": str(exc)
    }


# ========================================================================
# STARTUP/SHUTDOWN EVENTS
# ========================================================================

@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Credit Scoring API started")
    logger.info(f"üìä Model features: {predictor.metadata['n_features']}")
    logger.info("üìñ Documentation: http://localhost:8000/docs")


@app.on_event("shutdown")
async def shutdown_event():
    logger.info("üõë Credit Scoring API shutting down")


# ========================================================================
# RUN SERVER
# ========================================================================

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
